#1 INSTALL
-----------
wget https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.5.2.zip
unzip elasticsearch-1.5.2.zip
./bin/elasticsearch

curl -X GET http://localhost:9200/
{
  "status" : 200,
  "name" : "Amelia Voght",
  "cluster_name" : "elasticsearch",
  "version" : {
    "number" : "1.5.2",
    "build_hash" : "62ff9868b4c8a0c45860bebb259e21980778ab1c",
    "build_timestamp" : "2015-04-27T09:21:06Z",
    "build_snapshot" : false,
    "lucene_version" : "4.10.4"
  },
  "tagline" : "You Know, for Search"
}

1 node is one jvm, which automatically forms a 1node cluster
starting another node, will ping and join it, forming a 2 node cluster
shards are for partitioning data across nodes
replications are duplicating data across nodes

#2 SHARDS
-----------
make 4 shards of a new index 'books'  - s1, s2, s3, s4  

curl -X PUT http://localhost:9200/books -d '{"index.number_of_shards":4}'
{"acknowledged":true}

#3 REPLICAS
------------
make one copy of a shard to another 
s1s2 s2s4 s3s1 s4s3

curl -X PUT http://localhost:9200/books/_settings -d '{"index.number_of_replicas":1}'
{"acknowledged":true}

#4 CRUD
-------

curl -XPUT http://localhost:9200/books/book/1 -d '{"title" : "100 days of cholera", "author" : "Garcia Marquez", "language" : "spanish" }'
curl -XGET http://localhost:9200/books/book/1                                                                                          
{"_index":"books","_type":"book","_id":"1","_version":1,"found":true,"_source":{"title" : "100 days of cholera", "author" : "Garcia Marquez", "language" : "spanish" }}%    
curl -XDELETE http://localhost:9200/books/book/1

curl -xGET http://localhost:9200/books/book/_search -d {query json}


Lucene is doing the heavy lifting.
Each Shard is a Lucence index containing the inverted index (word1 -[doc1, doc2, doc3], word2 - [doc2, doc4], ...)


Filters do not contribute to score, they act on results already fetched/: