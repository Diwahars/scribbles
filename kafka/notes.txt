QUICKIE:
********

tar -xzf kafka_2.10-0.8.2.0.tgz
cd kafka_2.10-0.8.2.0
bin/zookeeper-server-start.sh config/zookeeper.properties
bin/kafka-server-start.sh config/server.properties

#single-node:
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
bin/kafka-topics.sh --list --zookeeper localhost:2181
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning

#multi-node 
 
config/server-1.properties:
    broker.id=1
    port=9093
    log.dir=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    port=9094
    log.dir=/tmp/kafka-logs-2

bin/kafka-server-start.sh config/server-1.properties &
bin/kafka-server-start.sh config/server-2.properties &
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
---------------------------------------------------------------------------------------------------------------------

PRINCIPLES:
**********
'topic' is a logical unit for creation/consumption of messages
topic is made up of 'partitions', an append-only,immutable commit logs
'producers' select a partition to dump a message based on their distribution choice.
messages in partitions are retained based on retention policies
1 complete partition per server
all partitions are replicated across servers
1 partition in a server is leader handling all read/writes, others passively replicated for failover

'consumers' read from partitions using 'offset', just a counter on where they are in the log
consumers can read multiple times from same parition by resetting the offset
consumers are grouped together into groups

only one consumer is guranteed to receive a message in a group, no duplicate receipt
'point': if all consumers belong to same group, they are load balanced within group for every message
'broadcast': if all consumers belong to different groups , they are distributed across groups for every message

1 partition/1 consumer always -> strong ordering

Messages sent by a producer to a particular topic partition will be appended in the order they are sent. 
That is, if a message M1 is sent by the same producer as a message M2, and M1 is sent first, then M1 will have a lower offset than M2 and appear earlier in the log.
A consumer instance sees messages in the order they are stored in the log.
For a topic with replication factor N, we will tolerate up to N-1 server failures without losing any messages committed to the log.
there cannot be more consumer instances than partitions.

GIST
****
topic -> 
	'Parallelism' - N partitions [1 partition/server, 1 partition/consumer (strong ordering)]
	'Replication' - Each partition in N is replicated across N servers with one as leader for R/W, other just Read








