1) non-personalised average:  just a average of ratings by all users for a movie
2) non-personalised product association:
    probability of buying X and Y together = P(X & Y)/P(X)P(Y) 
    probability of buying X -> P(X) = sales of X item/total sales of all items
    The above formula avoids the issue of a popular article like bread taking over the association.
    Association must be specific like anchovi paste+garlic, diaper+napkins
---------------------------------------------------------------------------------------------------------------------    
3) data collection is by building user preference model (explicit/implicit)
    3.1) explicit -> star ratings, review,thumbs and likes
    3.2) implicit -> buy, follow, track
---------------------------------------------------------------------------------------------------------------------    
4) ranking normalisation:
    recommenders should not be high-risk, high-return with low confidence level     
    4.1) damped mean:  
    Take every new item rating as middle (3 in 1..5), every rating that comes in is a piece of evidence to change it.
    this avoids a few ratings driving the final rating.
    
    4.2) sites like Hacker news, Reddit..etc all have their own custom formulae for ranking with time decay, penalties, damping.
            Reddit uses a logirthimic dampener to raise ratings 1, 100, 1000,10000 
            Hacker news uses penalties for controversial articles
            Reddit uses binomial distribution for comments ranking.
---------------------------------------------------------------------------------------------------------------------    
5) user-item based recommenders:

   5.0) intro:
        explicit/implicit user ratings/interests against content attributes
        build a vector of keyword preferences
        TFIDF - term frequency inverse document frequency
        case based reasoning - filtering a camera by specs like pixels,zoom etc. Similar to mobile deals wizard.
        longterm - build user profile based on content attributes.
        shortterm - ephemeral just apply at that time with database of cases.
   5.1) TF*IDF:
        TF -> term frequency -> no of times a term occurs in a document
        IDF -> inverse document frequency -> log (no of docs/no of docs with term)
        this stops very common words like 'the/is/was/..' and identifies real core words.
   
   5.2) Keyword vector:
        Vector space model with many dimensions, for eg
        user-taste vector     U = 20*romance+20*tomhanks+50*action (3d vector)
        castaway movie vector M = 34*romance+60*tomhanks+6*action
        cos angle between U & M vectors gives the user preference to the movie. cos = U.M/[M][U]
        user profile vector is built from his/her previous movie ratings, weightage of vector attributes is a tricky business.
        user profile can be permanent, decaying, shifting with changing movie preferences.
--------------------------------------------------------------------------------------------------------------    

6) user based recommenders:
   6.1) collaborative filtering:
        
        6.1.1) formula1:
        P(a,i) = sum[r(u,i)* w(a,u)] where u is{1->n}  / sum(w(a,u)

        Prediction of rating of item 'i' for user 'a' =  sum of (item i ratings given by other users multiplied by their affinity to user a)/sum of the affinity weights

        6.1.2) formula2:
        P(a,i) = avg(r(a)) + {sum[{r(u,i)-avg(r(u))}* w(a,u)]/ sum(w(a,u)}            

        Prediction = avg rating by user 'a' for all items +
                     sum of deviation of item i rating from other users
                     multiplied by affinity
                     divided by sum of affinity weights    

6) user-user based recommenders:
   6.1) collaborative filtering: SIMILARITY FUNCTIONS AND PREDICTIONS BASED ON IT.
        
        6.1.1) RATING PREDICTION 1:
        P(a,i) = sum[r(u,i)* w(a,u)] where u is{1->n}  / sum(w(a,u)

        Prediction of rating of item 'i' for user 'a' =  
                     sum of (item i ratings given by other users multiplied by their affinity to user a)
                     divided by sum of the affinity weights

        -----------------------------------------------------------------------------------------------------             
        6.1.2) RATING PREDICTION 2:using normalisation:
               considers user 'a' personal rating range (can be a happy 4 pointer or grumpy 2pointer always):
        
        P(a,i) = avg(r(a)) + {sum[{r(u,i)-avg(r(u))}* w(a,u)]/ sum(w(a,u)}            

        Prediction = avg rating by user 'a' for all items +
                     sum of deviation of item i's rating considering user u's rating scale preferences
                     multiplied by affinity
                     divided by sum of affinity weights
        -----------------------------------------------------------------------------------------------------
        6.1.3) RATING PREDICTION 3: using Z Score: for a user u and item i
            Z(u,i) = r(u,i)-avg(r(u))/stdDev(u)
            P(a,i) = avg(a)+ std(u)*sum[z(u,i)*w(a,u)]*stdDev(a)/sum(w(a,u))
        -----------------------------------------------------------------------------------------------------

        6.1.4) Similarity function:

            Pearson Correlation - affinity weight between users x and y 
            w(x,y) = sum{[r(x,i)-avg(r(x))]*[r(y,i)-avg(r(y))]/stdDev(x)*stdDev(y)} where i=1->m common items  

            Vector/cosine Similarity - cos of angle between user vectors on common items    
--------------------------------------------------------------------------------------------------------------                
7) item-item based recommenders:
   for eg in Amazon:
   user-user recommenders dont work out when you have a huge item base with few rankings, leading to sparsity 
   computation becomes heavy when number of users is high

   







        
           











